hydra.Prms-testRequirement = "Test to validate udf creation and deletion from embedded mode ";
hydra.Prms-testDescription = "The test will create function using udf from embedded mode and then access the created function through
 embedded mode ,jdbc connection and smart connector mode.
 Then stop start the cluster and again access the already persisted functions in all modes.
 Drop the functions and access it in all modes but with expected exception .";

INCLUDE $JTESTS/io/snappydata/hydra/northwind/startDualModeCluster.conf;
//create the user provided udfs in embedded mode.
 INITTASK   taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSnappyJob
            io.snappydata.hydra.cluster.SnappyPrms-jobClassNames = io.snappydata.hydra.deployPkgUDF.CreateDropUDFSnappyJob
            io.snappydata.hydra.cluster.SnappyPrms-appPropsForJobServer = "udf1=MyUDF3,udf2=MyUDF4,udf3=MyUDF5,isDropUDFFunction=false,jarPath=${jarPath}"
            io.snappydata.hydra.cluster.SnappyPrms-userAppJar = snappydata-store-scala-tests*tests.jar
            threadGroups = snappyThreads;


//Access them in embedded mode
 INITTASK   taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSnappyJob
            io.snappydata.hydra.cluster.SnappyPrms-jobClassNames = io.snappydata.hydra.deployPkgUDF.AccessUdfSnappyJob
            io.snappydata.hydra.cluster.SnappyPrms-appPropsForJobServer = "udf1=MyUDF3,udf2=MyUDF4,udf3=MyUDF5,argNum=25,argStr=snappydata,isException=false"
            io.snappydata.hydra.cluster.SnappyPrms-userAppJar = snappydata-store-scala-tests*tests.jar
            threadGroups = snappyThreads;


//Access them through jdbc connection
INITTASK    taskClass = io.snappydata.hydra.deployPkgUDF.SnappyDeployUnDeployTest taskMethod  = HydraTask_executeUDFFunction
            io.snappydata.hydra.deployPkgUDF.SnappyDeployUnDeployPrms-udfName = MyUDF3 MyUDF4 MyUDF5
            io.snappydata.hydra.deployPkgUDF.SnappyDeployUnDeployPrms-isExpectedExecption = false
            threadGroups = leadThreads
            ;

//Access them in smart-connector mode
INITTASK    taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSparkJob
            io.snappydata.hydra.cluster.SnappyPrms-sparkJobClassNames = io.snappydata.hydra.deployPkgUDF.AccessUdfSparkApp
            io.snappydata.hydra.cluster.SnappyPrms-userAppArgs = "MyUDF3 MyUDF4 MyUDF5 25 snappydata false"
            threadGroups = snappyThreads
            ;

//stop-start the cluster
INITTASK   taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_stopSnappyCluster
           threadGroups = snappyThreads;

INITTASK    taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_startSnappyCluster
            threadGroups = snappyThreads;

//Access the created functions again
//Access them through jdbc connection
INITTASK    taskClass = io.snappydata.hydra.deployPkgUDF.SnappyDeployUnDeployTest taskMethod  = HydraTask_executeUDFFunction
            io.snappydata.hydra.deployPkgUDF.SnappyDeployUnDeployPrms-udfName = MyUDF3 MyUDF4 MyUDF5
            io.snappydata.hydra.deployPkgUDF.SnappyDeployUnDeployPrms-isExpectedExecption = false
            threadGroups = leadThreads
            ;

//Access them in embedded mode
 INITTASK   taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSnappyJob
            io.snappydata.hydra.cluster.SnappyPrms-jobClassNames = io.snappydata.hydra.deployPkgUDF.AccessUdfSnappyJob
            io.snappydata.hydra.cluster.SnappyPrms-appPropsForJobServer = "udf1=MyUDF3,udf2=MyUDF4,udf3=MyUDF5,argNum=25,argStr=snappydata,isException=false"
            io.snappydata.hydra.cluster.SnappyPrms-userAppJar = snappydata-store-scala-tests*tests.jar
            threadGroups = snappyThreads;

//Access them through smart-connector mode
INITTASK    taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSparkJob
            io.snappydata.hydra.cluster.SnappyPrms-sparkJobClassNames = io.snappydata.hydra.deployPkgUDF.AccessUdfSparkApp
            io.snappydata.hydra.cluster.SnappyPrms-userAppArgs = "MyUDF3 MyUDF4 MyUDF5 25 snappydata false "
            threadGroups = snappyThreads
            ;

//drop the user provided udfs in embedded mode.
 INITTASK   taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSnappyJob
            io.snappydata.hydra.cluster.SnappyPrms-jobClassNames = io.snappydata.hydra.deployPkgUDF.CreateDropUDFSnappyJob
            io.snappydata.hydra.cluster.SnappyPrms-appPropsForJobServer = "udf1=MyUDF3,udf2=MyUDF4,udf3=MyUDF5,isDropUDFFunction=true,jarPath=${jarPath}"
            io.snappydata.hydra.cluster.SnappyPrms-userAppJar = snappydata-store-scala-tests*tests.jar
            threadGroups = snappyThreads;

//Access the created functions again

//Access them through jdbc connection, this time they should get exception
INITTASK    taskClass = io.snappydata.hydra.deployPkgUDF.SnappyDeployUnDeployTest taskMethod  = HydraTask_executeUDFFunction
            io.snappydata.hydra.deployPkgUDF.SnappyDeployUnDeployPrms-udfName = MyUDF3 MyUDF4 MyUDF5 MyUDF6 MyUDF7
            io.snappydata.hydra.deployPkgUDF.SnappyDeployUnDeployPrms-isExpectedExecption = true
            threadGroups = leadThreads
            ;

//Access them through snappy-job, this time they should get exception
 INITTASK   taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSnappyJob
            io.snappydata.hydra.cluster.SnappyPrms-jobClassNames = io.snappydata.hydra.deployPkgUDF.AccessUdfSnappyJob
            io.snappydata.hydra.cluster.SnappyPrms-appPropsForJobServer = "udf1=MyUDF3,udf2=MyUDF4,udf3=MyUDF5,argNum=25,argStr=snappydata,isException=true"
            io.snappydata.hydra.cluster.SnappyPrms-userAppJar = snappydata-store-scala-tests*tests.jar
            threadGroups = snappyThreads;

//Access them through smart-connector mode,  this time they should get exception
INITTASK    taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSparkJob
            io.snappydata.hydra.cluster.SnappyPrms-sparkJobClassNames = io.snappydata.hydra.deployPkgUDF.AccessUdfSparkApp
            io.snappydata.hydra.cluster.SnappyPrms-userAppArgs = "MyUDF3 MyUDF4 MyUDF5 25 snappydata true"
            threadGroups = snappyThreads
            ;

INCLUDE $JTESTS/io/snappydata/hydra/northwind/stopDualModeCluster.conf;

hydra.Prms-totalTaskTimeSec           = 900;
hydra.Prms-maxResultWaitSec           = 3600;
io.snappydata.hydra.cluster.SnappyPrms-serverMemory = 4g;

io.snappydata.hydra.cluster.SnappyPrms-forceStart = true;
io.snappydata.hydra.cluster.SnappyPrms-userAppJar = snappydata-store-scala-tests*tests.jar;